#!/usr/local/bin/python3
# Copyright (c) KMG. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
##
"""
SBK AI Analysis Module

This module provides AI-powered analysis capabilities for storage benchmark results.
It extends the SbkMultiCharts class to add AI-generated performance analysis
for storage system benchmarks, including throughput and latency analysis.

The module integrates with Hugging Face models to provide intelligent insights
into storage performance metrics.
"""
from typing import final

from src.charts import constants
from src.charts.multicharts import SbkMultiCharts
from src.custom_ai.hugging_face import HuggingFace
from openpyxl.styles import Font, Border, Side, Alignment   
import textwrap
from src.stat.storage import StorageStat
# Log the full exception for debugging
import traceback

# Warning message about AI-generated content reliability
warning_msg = ("The AI may hallucinate !. "
              "The summary generated by generative AI models may not be complete and accurate. "
              "It's recommended to analyze the graphs along with the generated summary.")

class SbkAI(SbkMultiCharts):
    """
    SBK AI Analysis class that extends SbkMultiCharts to provide AI-powered analysis.
    
    This class adds AI-generated performance analysis to storage benchmark results,
    including throughput and latency analysis using Hugging Face models.
    
    Attributes:
        version (str): Version information for the benchmark.
        file (str): Path to the benchmark results file.
        ai (HuggingFace): Instance of HuggingFace for AI analysis.
    """
    
    def __init__(self, version, file):
        """
        Initialize the SbkAI instance.
        
        Args:
            version (str): Version information for the benchmark.
            file (str): Path to the benchmark results file.
        """
        super().__init__(version, file)
        self.ai = HuggingFace()

    @final
    def get_columns_values(self, ws):
        """
        Extract column values from a worksheet, excluding metadata columns.
        
        Args:
            ws (openpyxl.worksheet.worksheet.Worksheet): The worksheet to extract data from.
            
        Returns:
            dict: Dictionary mapping column names to their values.
        """
        columns = self.get_columns_from_worksheet(ws)
        ret = dict()
        for col_name, col_idx in columns.items():
            if col_name not in [constants.ID, constants.HEADER, constants.TYPE,
                              constants.STORAGE, constants.ACTION, constants.LATENCY_TIME_UNIT]:
                values = []
                for row in range(2, ws.max_row + 1):
                    cell_value = ws.cell(row=row, column=col_idx).value
                    values.append(cell_value)
                ret[col_name] = values
        return ret

    def get_storage_stats(self):
        """
        Collect and organize storage statistics from all worksheets.
        
        Returns:
            list: List of StorageStat objects containing performance metrics
                  for each storage system in the benchmark.
        """
        stats = list()
        for name in self.wb.sheetnames:
            if self.is_r_num_sheet(name):
                ws = self.wb[name]
                storage = self.get_storage_name(ws)
                timeunit = self.get_time_unit(ws)
                action = self.get_action_name(ws)
                # Get all the columns of R<Count>
                regular = self.get_columns_values(ws)
                # Get all the columns of T<Count>
                t_name = self.get_t_num_sheet_name(name)
                ws = self.wb[t_name]
                total = self.get_columns_values(ws)
                stats.append(StorageStat(storage, timeunit, action, regular, total))
        return stats

    def create_summary_sheet(self):
        """
        Create a summary sheet with AI-generated performance analysis.
        
        This method extends the parent class's create_summary_sheet method to add
        AI-generated analysis of throughput and latency metrics.
        
        Returns:
            openpyxl.worksheet.worksheet.Worksheet: The created or modified worksheet,
            or None if creation failed.
        """
        sheet = super().create_summary_sheet()
        if sheet is None:
            print("Warning: Could not create summary sheet")
            return None

        # Set storage statistics for AI analysis
        self.ai.set_storage_stats(self.get_storage_stats())
        
        # Get throughput analysis from AI
        throughput_status, throughput_analysis = self.ai.get_throughput_analysis()
        if not throughput_status:
            print(f"Error in throughput analysis: {throughput_analysis}")
            return sheet

        # Get latency analysis from AI
        latency_status, latency_analysis = self.ai.get_latency_analysis()
        if not latency_status:
            print(f"Error in latency analysis: {latency_analysis}")
            return sheet

        # Format and add AI analysis to the worksheet
        try:
            # Configure column H width to accommodate 120 characters
            sheet.column_dimensions['H'].width = 120 * 0.90
            
            # Add AI warning section with proper formatting
            max_row = sheet.max_row + 3  # Add spacing before the warning
            
            # Format and add the warning message
            warn_cell = sheet.cell(row=max_row, column=8)
            warn_cell.value = warning_msg
            warn_cell.font = Font(size=16, bold=True, color="FFFF0000")  # Red bold text
            warn_cell.alignment = Alignment(wrap_text=True, vertical='top')
            
            # Calculate optimal row height for the warning message
            warning_wrapped_lines = []
            for line in warning_msg.split('\n'):
                warning_wrapped_lines.extend(textwrap.wrap(line, width=120))
            
            # Set row height with minimum of 35 points
            warn_row_height = max(35, len(warning_wrapped_lines) * 35)
            sheet.row_dimensions[max_row].height = warn_row_height

            # Add AI Performance Analysis section header
            max_row = sheet.max_row + 2
            title_cell = sheet.cell(row=max_row, column=7)
            title_cell.value = "AI Performance Analysis"
            title_cell.font = Font(size=18, bold=True, color="FF0000")
            
            # Add model description
            dec_cell = sheet.cell(row=max_row, column=8)
            dec_cell.value = self.ai.get_model_description()
            dec_cell.font = Font(size=16, color="00CF00")  # Green text for model info

            # Add Throughput Analysis section
            throughput_header_row = max_row + 2
            cell = sheet.cell(row=throughput_header_row, column=7)
            cell.value = "Throughput Analysis"
            cell.font = Font(size=16, bold=True, color="EE00FF")  # Purple header
            
            # Add throughput analysis content with formatting
            cell = sheet.cell(row=throughput_header_row, column=8)
            cell.value = throughput_analysis
            cell.font = Font(size=14, color="FF800000")  # Dark red text
            cell.border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            cell.alignment = Alignment(wrap_text=True, vertical='top')
            
            # Calculate and set optimal row height for throughput analysis
            wrapped_lines = []
            for line in throughput_analysis.split('\n'):
                wrapped_lines.extend(textwrap.wrap(line, width=120))
            
            row_height = max(25, len(wrapped_lines) * 25)
            sheet.row_dimensions[throughput_header_row].height = row_height

            # Add Latency Analysis section
            latency_row = sheet.max_row + 1
            
            # Format and add latency analysis header
            cell = sheet.cell(row=latency_row, column=7)
            cell.value = "Latency Analysis"
            cell.font = Font(size=16, bold=True, color="00AA00")  # Green header
            
            # Add latency analysis content with formatting
            cell = sheet.cell(row=latency_row, column=8)
            cell.value = latency_analysis
            cell.font = Font(size=14, color="FF000080")  # Dark blue text
            cell.border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            cell.alignment = Alignment(wrap_text=True, vertical='top')
            
            # Calculate and set optimal row height for latency analysis
            latency_wrapped_lines = []
            for line in latency_analysis.split('\n'):
                latency_wrapped_lines.extend(textwrap.wrap(line, width=120))
            
            latency_row_height = max(25, len(latency_wrapped_lines) * 25)
            sheet.row_dimensions[latency_row].height = latency_row_height

        except Exception as e:
            print(f"Error adding analysis to summary sheet: {str(e)}")
            traceback.print_exc()
            
        return sheet


    def create_graphs(self):
        """
        Generate all performance graphs and AI analysis for the benchmark results.
        
        This method orchestrates the creation of various performance graphs and
        AI analysis, then saves the results to the output file.
        
        The method creates the following types of graphs:
        - Throughput graphs (MB/s and records/s)
        - Latency comparison graphs
        - Write/Read metrics graphs
        - Percentile analysis graphs
        - Comparative analysis graphs
        
        After generating all graphs and analysis, it saves the results to the
        Excel workbook and prints a confirmation message.
        """
        if self.check_time_units():
            # Create summary sheet with AI analysis
            self.create_summary_sheet()
            
            # Generate throughput graphs
            self.create_multi_throughput_mb_graph()
            self.create_multi_throughput_records_graph()
            
            # Generate latency analysis graphs
            self.create_all_latency_compare_graphs()
            self.create_multi_latency_compare_graphs()
            self.create_multi_latency_graphs()
            
            # Generate write/read metrics graphs
            self.create_multi_write_read_records_graph()
            self.create_multi_write_read_mb_graph()
            self.create_multi_write_read_timeout_events_graph()
            self.create_multi_write_read_timeout_events_per_sec_graph()
            
            # Generate percentile analysis
            self.create_total_multi_latency_percentile_graphs()
            self.create_total_multi_latency_percentile_count_graphs()
            
            # Generate comparative analysis graphs
            self.create_total_mb_compare_graph()
            self.create_total_throughput_mb_compare_graph()
            self.create_total_throughput_records_compare_graph()
            self.create_total_min_latency_compare_graph()
            self.create_total_avg_latency_compare_graph()
            self.create_total_max_latency_compare_graph()
            self.create_total_write_read_timeout_events_compare_graph()
            
            # Save the workbook with all the generated content
            self.wb.save(self.file)
            print(f"File updated with graphs and AI documentation: {self.file}")
