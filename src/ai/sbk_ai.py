#!/usr/local/bin/python3
# Copyright (c) KMG. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
##
"""
SBK AI Analysis Module

This module provides AI-powered analysis of storage benchmark results through
the SbkAI class. It enables automated generation of performance insights,
including throughput and latency analysis, by leveraging various AI backends.

Supported AI Backends:
- Hugging Face (default)
- LM Studio (local models)
- Ollama (local LLMs)
- No-AI (stub implementation)

Key Features:
- Automated performance analysis of benchmark results
- Support for multiple AI providers
- Threaded execution for parallel analysis
- Configurable timeouts and error handling
"""
import time
from typing import final
import threading
import sys

from openpyxl import load_workbook

from src.ai.discover import discover_custom_ai_classes
from src.charts import constants
from src.charts.utils import is_r_num_sheet, get_columns_from_worksheet, get_storage_name_from_worksheet
from src.charts.utils import get_time_unit_from_worksheet, get_action_name_from_worksheet
from src.sheets import constants as sheets_constants
from openpyxl.styles import Font, Border, Side, Alignment   
import textwrap

from src.stat.storage import StorageStat
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor
from src.rag.sbk_rag import SbkSimpleRAGPipeline

# Log the full exception for debugging
import traceback

# Excel formatting constants
class ExcelColors:
    RED_BOLD = "FFFF0000"
    GREEN = "00CF00"
    PURPLE = "EE00FF"
    DARK_RED = "FF800000"
    GREEN_HEADER = "00AA00"
    DARK_BLUE = "FF000080"
    BLUE = "0000FF"
    DARK_GREEN = "008000"
    DARK_MAGENTA = "8B008B"
    SADDLE_BROWN = "8B4513"
    TITLE_RED = "FF0000"

# Warning message about AI-generated content reliability
warning_msg = ("The AI may hallucinate !. "
              "The summary generated by generative AI models may not be complete and accurate. "
              "It's recommended to analyze the graphs along with the generated summary.")

DEFAULT_TIMEOUT_SECONDS = 120

def get_t_num_sheet_name(r_num_name):
    """
    Return the corresponding T-sheet name for an R-sheet name.

    Example: 'R1' -> 'T1'

    Parameters:
        r_num_name (str): R-sheet name

    Returns:
        str: corresponding T-sheet name
    """
    return sheets_constants.T_PREFIX + r_num_name[1:]


def get_columns_values(ws):
    """
    Extract column values from a worksheet, excluding metadata columns.

    This function processes the data in a worksheet to extract all relevant
    performance metrics while excluding metadata columns like ID, HEADER, TYPE,
    STORAGE, ACTION, and LATENCY_TIME_UNIT.

    Args:
        ws (openpyxl.worksheet.worksheet.Worksheet): The worksheet to extract data from.

    Returns:
        dict: Dictionary mapping column names to their values as lists
    """
    columns = get_columns_from_worksheet(ws)
    ret = dict()
    for col_name, col_idx in columns.items():
        if col_name not in [constants.ID, constants.HEADER, constants.TYPE,
                          constants.STORAGE, constants.ACTION, constants.LATENCY_TIME_UNIT]:
            values = []
            for row in range(2, ws.max_row + 1):
                cell_value = ws.cell(row=row, column=col_idx).value
                values.append(cell_value)
            ret[col_name] = values
    return ret


@final
class SbkAI:
    """
    SBK AI Analysis Engine
    
    This class provides AI-powered analysis of storage benchmark results.
    It supports multiple AI backends and provides methods for generating
    performance insights, including throughput and latency analysis.
    
    The engine handles the complete workflow from loading benchmark data,
    running AI analyses in parallel, formatting results into Excel sheets,
    and saving the enhanced workbook with performance insights.

    Attributes:
        classes (dict): Dictionary of available AI backend classes discovered at runtime
        ai_instance_map (dict): Mapping of AI instances by name for easy access
        subparsers: Command-line argument subparsers for configuring different AI backends
        file (str): Path to the output Excel file being processed
        ai_instance: Active AI backend instance currently in use
        web: Web interface component (if enabled)
        timeout_seconds (int): Timeout for AI operations in seconds, default 120
        no_threads (bool): Flag to disable threaded execution for debugging purposes, default False
    """

    def __init__(self):
        """
        Initialize the SbkAI analysis engine.

        This constructor discovers all available AI backend classes and sets up
        the basic configuration for analysis execution.

        The discovery process uses reflection to find all classes that implement
        the AI interface in the custom_ai module.
        """
        self.classes = discover_custom_ai_classes()
        self.ai_instance_map = dict()
        self.subparsers = None
        self.input_files = None
        self.file =  None
        self.ai_instance = None
        self.web = None
        self.timeout_seconds = DEFAULT_TIMEOUT_SECONDS
        self.no_threads = False
        self.chat_mode = False
        self.rag_pipeline = None

    def add_args(self, parser):
        """
        Add command-line arguments for AI configuration to the argument parser.

        This method configures the command-line interface with options specific
        to AI analysis, including timeout settings and threading controls.

        Args:
            parser (argparse.ArgumentParser): The argument parser to add arguments to

        Side Effects:
            - Adds timeout and threading configuration options
            - Registers subparsers for each available AI backend class
        """
        parser.add_argument("-secs", "--seconds", help=f"Timeout seconds, default : {self.timeout_seconds}",
                            default=self.timeout_seconds)
        parser.add_argument("-nothreads", "--nothreads", help="Disable parallel threads (default: threads enabled)", 
                            action="store_true", default=False)
        parser.add_argument("-chat", "--chat", help="Start interactive chat mode with AI", 
                            action="store_true", default=False)
        self.subparsers = parser.add_subparsers(dest="ai_class", help="Available GenAI commands", required=False)
        parser.set_defaults(ai_class=None)
        for name, cls in self.classes.items():
            try:
                subp = self.subparsers.add_parser(name)
                self.ai_instance_map[name.lower()] = cls()
                self.ai_instance_map[name.lower()].add_args(subp)
            except Exception:
                # don't break arg registration if a class has issues; log for debugging
                traceback.print_exc()


    def parse_args(self, args):
        """
        Parse command-line arguments and configure the AI instance.

        This method processes the parsed command-line arguments to set up
        the analysis engine with appropriate configuration and activate
        the selected AI backend.

        Args:
            args (argparse.Namespace): Parsed command-line arguments
            
        Side Effects:
            - Sets the output file path
            - Configures timeout (converted to int) and threading settings
            - Activates the selected AI backend instance if specified
            - Initializes RAG pipeline with input CSV files if available
        """
        self.timeout_seconds = int(args.seconds) if hasattr(args, 'seconds') and args.seconds is not None else DEFAULT_TIMEOUT_SECONDS
        self.file = args.ofile
        self.no_threads = args.nothreads
        self.chat_mode = args.chat

        if args.ai_class:
            self.ai_instance = self.ai_instance_map[args.ai_class.lower()]
            self.ai_instance.parse_args(args)

    def _initialize_rag_pipeline(self):
        """
        Initialize the RAG pipeline with storage statistics.
        
        This method creates a RAG pipeline instance and ingests data from
        the storage statistics to provide context for AI analysis.
        Uses Simple RAG by default for maximum compatibility.
        """
        try:
            print("üéØ Using Simple RAG (ChromaDB-free) for maximum compatibility...")
            try:
                self.rag_pipeline = SbkSimpleRAGPipeline()
                if self.rag_pipeline.initialize():
                    # Ingest storage statistics data
                    if self.rag_pipeline.ingest_storage_stats(self.get_storage_stats()):
                        stats = self.rag_pipeline.get_collection_stats()
                        print(f"‚úÖ Simple RAG pipeline initialized successfully with {stats.get('document_count', 0)} data points")
                        print("üí° Simple RAG provides full functionality without external dependencies")
                        return
                    else:
                        print("‚ùå Failed to ingest storage statistics into Simple RAG pipeline")
                else:
                    print("‚ùå Failed to initialize Simple RAG pipeline")
                    
            except Exception as e:
                print(f"‚ùå Simple RAG pipeline failed: {str(e)}")
                self.rag_pipeline = None

        except Exception as e:
            print(f"‚ùå Error initializing RAG pipeline: {str(e)}")
            self.rag_pipeline = None

    def open(self, args):
        if self.ai_instance:
            self.ai_instance.open(args)


    def close(self, args):
        if self.ai_instance:
            self.ai_instance.close(args)
        
        # Clean up RAG pipeline if it exists
        if self.rag_pipeline:
            print("Closing RAG pipeline...")
            if self.rag_pipeline.close(cleanup_local_data=True):
                print("RAG pipeline closed successfully")
            else:
                print("Warning: Failed to close RAG pipeline properly")

    def load_workbook(self):
        """
        Load the Excel workbook from the specified file path.

        This method reads an existing Excel file and loads it into memory
        for further processing. It's typically called before any analysis
        or modification operations.

        Side Effects:
            - Loads the workbook into self.wb attribute
            - Raises IOError if file cannot be read

        Note:
            The workbook must exist and be in a valid Excel format.
        """
        self.wb = load_workbook(self.file)

    def save_workbook(self):
        """
        Save the current workbook to disk.

        This method writes any modifications made to the workbook back
        to the original file location. It should be called after all
        analysis and formatting operations are complete.

        Side Effects:
            - Writes the workbook to disk
            - Overwrites the original file

        Note:
            This operation will overwrite any existing data in the output file.
        """
        self.wb.save(self.file)


    def get_storage_stats(self):
        """
        Collect and organize storage statistics from all worksheets.
        
        This method processes each R-sheet in the workbook to extract
        performance metrics and organizes them into StorageStat objects.
        It handles both regular (R) and total (T) data sheets to provide
        comprehensive performance analysis.

        Returns:
            list: List of StorageStat objects containing performance metrics
                  for each storage system in the benchmark. Each object contains:
                  - Storage name
                  - Time unit
                  - Action type
                  - Regular performance metrics (from R sheets)
                  - Total performance metrics (from T sheets)

        Note:
            Only worksheets that match the R<number> pattern are processed.
        """
        stats = list()
        for name in self.wb.sheetnames:
            if is_r_num_sheet(name):
                ws = self.wb[name]
                storage = get_storage_name_from_worksheet(ws)
                timeunit = get_time_unit_from_worksheet(ws)
                action = get_action_name_from_worksheet(ws)
                # Get all the columns of R<Count>
                regular = get_columns_values(ws)
                # Get all the columns of T<Count>
                t_name = get_t_num_sheet_name(name)
                ws = self.wb[t_name]
                total = get_columns_values(ws)
                stats.append(StorageStat(storage, timeunit, action, regular, total))
        return stats

    def add_ai_analysis(self):
        """
        Create a summary sheet with AI-generated performance analysis.
        
        This method orchestrates the execution of all available AI analysis
        methods in parallel to improve performance. It collects throughput,
        latency, total MB, and percentile histogram analysis from the active
        AI backend and formats the results into Excel cells with appropriate styling.

        The method handles both sequential and parallel execution modes based
        on the no_threads configuration flag, with configurable timeouts to
        prevent hanging operations.
        
        Returns:
            bool: True if analysis was successful, False otherwise

        Side Effects:
            - Modifies the workbook by adding AI analysis content to Summary sheet
            - Sets various cell formatting including fonts, borders, and alignment
            - Adjusts row heights based on content length

        Note:
            This method requires the workbook to be loaded and an AI instance
            to be configured before calling.
        """
        # Set storage statistics for AI analysis
        self.ai_instance.set_storage_stats(self.get_storage_stats())


        def run_analysis(function_name):
            """
            Execute a single AI analysis method and handle exceptions.

            This helper function wraps the execution of individual AI methods
            to provide consistent error handling and return format.

            Args:
                function_name (str): Name of the method to execute

            Returns:
                tuple: (method_name, result_tuple) where result_tuple is
                       (success_bool, analysis_content_or_error_message)
            """
            try:
                method = getattr(self.ai_instance, function_name)
                ret = method()
                return function_name,ret
            except Exception as e:
                print(f"Exception in {function_name}: {str(e)}")
                return function_name, (False, str(e))
        
        # List of AI analysis methods to run in parallel
        analysis_methods = [
            'get_throughput_analysis',
            'get_latency_analysis',
            'get_total_mb_analysis',
            'get_percentile_histogram_analysis',
        ]

        # Run all analysis methods in parallel
        print("Starting AI analysis. This may take a few minutes...", flush=True)
        start_time = time.time()

        # Create a dictionary to store results
        results = {}

        if self.no_threads:
            # Run analysis methods sequentially for debugging or simpler execution
            print("Running analysis sequentially (no threads)...")
            for method_name in analysis_methods:
                try:
                    print(f"Running {method_name}...")
                    result_method, result = run_analysis(method_name)
                    results[result_method] = result
                    print(f"‚úì Completed {result_method}")

                    # Check timeout after each method
                    if (time.time() - start_time) > self.timeout_seconds:
                        print(f"‚ö†Ô∏è Timeout after {self.timeout_seconds} seconds")
                        # Mark remaining methods as timed out
                        for remaining in analysis_methods[analysis_methods.index(method_name) + 1:]:
                            results[remaining] = (False, "Analysis timed out")
                        break

                except Exception as e:
                    print(f"‚ö†Ô∏è Error in {method_name}: {str(e)}")
                    results[method_name] = (False, str(e))
        else:
            # Run analysis methods in parallel using ThreadPoolExecutor for better performance
            print(f"Running analysis in parallel with timeout: {self.timeout_seconds} seconds...")
            with ThreadPoolExecutor(max_workers=len(analysis_methods)) as executor:
                # Submit all tasks and store futures
                future_to_method = {executor.submit(run_analysis, method): method
                                    for method in analysis_methods}

                # Process completed tasks as they finish
                while future_to_method and (time.time() - start_time) < self.timeout_seconds:
                    # Wait for the next future to complete, with a timeout
                    done, _ = concurrent.futures.wait(
                        future_to_method.keys(),
                        timeout=2.0,  # Check every 2 seconds for timeouts
                        return_when=concurrent.futures.FIRST_COMPLETED
                    )

                    # Process completed futures
                    for future in done:
                        method_name = future_to_method.pop(future)
                        try:
                            result_method, result = future.result(timeout=1.0)
                            results[result_method] = result
                            print(f"‚úì Completed {result_method}")
                        except concurrent.futures.TimeoutError:
                            print(f"‚ö†Ô∏è Timeout waiting for {method_name}, skipping...")
                            results[method_name] = (False, "Analysis timed out")
                        except Exception as e:
                            print(f"‚ö†Ô∏è Error in {method_name}: {str(e)}")
                            results[method_name] = (False, str(e))

                    # Print progress
                    remaining = len(future_to_method)
                    if remaining > 0:
                        print(f"‚è≥ Waiting for {remaining} more analysis tasks...")

                remaining = len(future_to_method)
                if remaining > 0:
                    print(f"‚ö†Ô∏è {remaining} analysis tasks Timeout !")
                    # Cancel any remaining futures
                    for future in future_to_method:
                        future.cancel()
                        method_name = future_to_method[future]
                        results[method_name] = (False, "Analysis timed out or failed")

        # Ensure all methods have a result
        for method_name in analysis_methods:
            if method_name not in results:
                results[method_name] = (False, "Analysis not completed")

        print(f"Analysis completed in {time.time() - start_time:.2f} seconds", flush=True)

       # Format and add AI analysis to the worksheet
        try:
            sheet = self.wb["Summary"]

            # Configure column H width to accommodate text
            sheet.column_dimensions['H'].width = 120 * 0.90
            
            # Add AI warning section with proper formatting
            max_row = sheet.max_row + 3  # Add spacing before the warning
            
            # Format and add the warning message
            warn_cell = sheet.cell(row=max_row, column=8)
            warn_cell.value = warning_msg
            warn_cell.font = Font(size=16, bold=True, color=ExcelColors.RED_BOLD)
            warn_cell.alignment = Alignment(wrap_text=True, vertical='top')
            
            # Calculate optimal row height for the warning message
            warning_wrapped_lines = []
            for line in warning_msg.split('\n'):
                warning_wrapped_lines.extend(textwrap.wrap(line, width=120))
            
            # Set row height with minimum of 35 points
            warn_row_height = max(35, len(warning_wrapped_lines) * 35)
            sheet.row_dimensions[max_row].height = warn_row_height

            # Add AI Performance Analysis section header
            max_row = sheet.max_row + 2
            title_cell = sheet.cell(row=max_row, column=7)
            title_cell.value = "AI Performance Analysis"
            title_cell.font = Font(size=18, bold=True, color=ExcelColors.TITLE_RED)
            
            # Add model description
            dec_cell = sheet.cell(row=max_row, column=8)
            dec_cell.value = self.ai_instance.get_model_description()[1]
            dec_cell.font = Font(size=16, color=ExcelColors.GREEN)

            # Add Throughput Analysis section
            throughput_header_row = max_row + 2
            cell = sheet.cell(row=throughput_header_row, column=7)
            cell.value = "Throughput Analysis"
            cell.font = Font(size=16, bold=True, color=ExcelColors.PURPLE)
            
            # Add throughput analysis content with formatting
            cell = sheet.cell(row=throughput_header_row, column=8)
            throughput_analysis = results['get_throughput_analysis'][1]
            cell.value = throughput_analysis
            cell.font = Font(size=14, color=ExcelColors.DARK_RED)
            cell.border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            cell.alignment = Alignment(wrap_text=True, vertical='top')
            
            # Calculate and set optimal row height for throughput analysis
            wrapped_lines = []
            for line in throughput_analysis.split('\n'):
                wrapped_lines.extend(textwrap.wrap(line, width=120))
            
            row_height = max(25, len(wrapped_lines) * 25)
            sheet.row_dimensions[throughput_header_row].height = row_height

            # Add Latency Analysis section
            latency_row = sheet.max_row + 1
            
            # Format and add latency analysis header
            cell = sheet.cell(row=latency_row, column=7)
            cell.value = "Latency Analysis"
            cell.font = Font(size=16, bold=True, color=ExcelColors.GREEN_HEADER)
            
            # Add latency analysis content with formatting
            cell = sheet.cell(row=latency_row, column=8)
            latency_analysis = results['get_latency_analysis'][1]
            cell.value = latency_analysis
            cell.font = Font(size=14, color="FF000080")
            cell.border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            cell.alignment = Alignment(wrap_text=True, vertical='top')
            
            # Calculate and set optimal row height for latency analysis
            latency_wrapped_lines = []
            for line in latency_analysis.split('\n'):
                latency_wrapped_lines.extend(textwrap.wrap(line, width=120))
            
            latency_row_height = max(25, len(latency_wrapped_lines) * 25)
            sheet.row_dimensions[latency_row].height = latency_row_height
            
            # Add Total MB Analysis section
            mb_row = sheet.max_row + 1
            
            # Format and add total MB analysis header
            cell = sheet.cell(row=mb_row, column=7)
            cell.value = "Total MB Analysis"
            cell.font = Font(size=16, bold=True, color=ExcelColors.BLUE)
            
            # Add total MB analysis content with formatting
            cell = sheet.cell(row=mb_row, column=8)
            mb_analysis = results['get_total_mb_analysis'][1]
            cell.value = mb_analysis
            cell.font = Font(size=14, color=ExcelColors.DARK_GREEN)
            cell.border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            cell.alignment = Alignment(wrap_text=True, vertical='top')
            
            # Calculate and set optimal row height for total MB analysis
            mb_wrapped_lines = []
            for line in mb_analysis.split('\n'):
                mb_wrapped_lines.extend(textwrap.wrap(line, width=120))
            
            mb_row_height = max(25, len(mb_wrapped_lines) * 25)
            sheet.row_dimensions[mb_row].height = mb_row_height
            
            # Add Percentile Histogram Analysis section
            percentile_row = sheet.max_row + 1  # Add an extra blank row
            
            # Format and add percentile histogram analysis header
            cell = sheet.cell(row=percentile_row, column=7)
            cell.value = "Percentile Histogram Analysis"
            cell.font = Font(size=16, bold=True, color=ExcelColors.DARK_MAGENTA)
            
            # Add percentile histogram analysis content with formatting
            cell = sheet.cell(row=percentile_row, column=8)
            percentile_analysis = results['get_percentile_histogram_analysis'][1]
            cell.value = percentile_analysis
            cell.font = Font(size=14, color=ExcelColors.SADDLE_BROWN)
            cell.border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            cell.alignment = Alignment(wrap_text=True, vertical='top')
            
            # Calculate and set optimal row height for percentile histogram analysis
            percentile_wrapped_lines = []
            for line in percentile_analysis.split('\n'):
                percentile_wrapped_lines.extend(textwrap.wrap(line, width=120))
            
            percentile_row_height = max(25, len(percentile_wrapped_lines) * 25)
            sheet.row_dimensions[percentile_row].height = percentile_row_height

        except Exception as e:
            print(f"Error adding analysis to summary sheet: {str(e)}")
            traceback.print_exc()
        
        return True

    def add_performance_details(self):
        """
        Generate all performance graphs and AI analysis for the benchmark results.
        
        This is the main entry point method that orchestrates the complete workflow:
        1. Loads the Excel workbook
        2. Runs AI analysis on performance data
        3. Saves the enhanced workbook with graphs and AI documentation
        
        The method creates various performance visualizations including:
        - Throughput graphs (MB/s and records/s)
        - Latency comparison graphs
        - Write/Read metrics graphs
        - Percentile analysis graphs
        - Comparative analysis graphs
        
        After generating all visualizations and AI insights, it saves the final
        enhanced workbook to disk.

        Side Effects:
            - Loads and modifies an Excel workbook
            - Saves the modified workbook to disk
            - Prints status messages during execution

        Note:
            This method should only be called when an AI backend is properly configured.
            If no AI instance is set, it will display a warning message and skip analysis.
        """
        if not self.ai_instance:
            print("AI is not enabled!. you can use the subcommands ["+" ".join(self.classes.keys())+"] to enable it.")
        else:
            self.load_workbook()
            if self.add_ai_analysis():
                print(f"File updated with graphs and AI documentation: {self.file}")
            self.save_workbook()

    def chat(self):
        """
        Start interactive chat mode with the AI instance.
        
        This method implements an interactive chat loop where users can:
        - Input queries in natural language
        - Get AI responses in a separate thread
        - Monitor the thread and print responses every 5 seconds
        - Exit with Control+D (EOF)
        
        The chat mode requires an AI instance to be configured. If no AI instance
        is available, it will display an error message and return.
        
        Side Effects:
            - Starts interactive command-line interface
            - Creates and manages threads for AI responses
            - Prints AI responses to stdout
            - Handles keyboard interrupts gracefully
        """

        if not self.chat_mode:
            return

        if not self.ai_instance:
            print("Error: No AI instance configured. Please specify an AI backend using the available subcommands.")
            print(f"Available AI backends: {', '.join(self.classes.keys())}")
            return

        storage_stats = self.get_storage_stats()

        if not storage_stats:
            print(f"Error: Storage stats are not available; check if the workbook {self.file} loaded properly or not!")
            return

        self._initialize_rag_pipeline()

        # Set RAG pipeline if available
        if self.rag_pipeline:
            self.ai_instance.set_rag_pipeline(self.rag_pipeline)

        print("\n=== SBK AI Chat Mode ===")
        print("Type your queries and press Enter twice to finish, or press Ctrl+D to exit.")
        print("Multiline input is supported - just press Enter twice when done typing.")
        
        # Show available storage systems if RAG is initialized
        if self.rag_pipeline and hasattr(self.rag_pipeline, 'get_storage_systems'):
            storage_systems = self.rag_pipeline.get_storage_systems()
            if storage_systems:
                print(f"\nüí° Available storage systems for comparison: {', '.join(storage_systems)}")
                print("You can ask questions like:")
                print("- 'Which storage system performs better?'")
                print("- 'Compare throughput between storage systems'")
                print("- 'What is the best storage system for high IOPS?'")
                print("- For complex queries, you can type multiple lines and press Enter twice when done.")
        
        print("========================\n")
        
        try:
            while True:
                try:
                    # Get user input (multiline support)
                    print("\nYou: ")
                    query_lines = []
                    while True:
                        try:
                            line = input()
                            if line.strip() == "" and len(query_lines) > 0:
                                # Empty line after some content means end of input
                                break
                            query_lines.append(line)
                        except EOFError:
                            # Ctrl-D pressed
                            if len(query_lines) == 0:
                                # Exit chat mode
                                print("\nüëã  Exiting chat mode...")
                                return
                            else:
                                # End current query
                                break
                    
                    query = "\n".join(query_lines).strip()
                    
                    if not query:
                        print("Please enter a valid query.")
                        continue
                    
                    # Start AI response in separate thread
                    response_thread = threading.Thread(
                        target=self._get_ai_response,
                        args=(query,),
                        daemon=True
                    )
                    response_thread.start()
                    
                    # Monitor the thread and print status every 5 seconds
                    while response_thread.is_alive():
                        print("\rü§î  AI is thinking...", end="", flush=True)
                        response_thread.join(timeout=5.0)
                        if response_thread.is_alive():
                            print("\rü§î  AI is thinking... (still processing)", end="", flush=True)
                    
                    print("\r", end="")  # Clear the thinking message
                    
                except EOFError:
                    # Control+D pressed
                    print("\n\nGoodbye! Exiting chat mode.")
                    break
                except KeyboardInterrupt:
                    print("\n\nChat interrupted. Use Control+D to exit.")
                    continue
                    
        except Exception as e:
            print(f"Error in chat mode: {str(e)}")
            traceback.print_exc()
    
    def _get_ai_response(self, query):
        """
        Get AI response for a given query and print it.
        
        This method runs in a separate thread to avoid blocking the main
        chat interface while waiting for AI responses.
        
        Args:
            query (str): The user's query to process
            
        Side Effects:
            - Calls the AI instance's get_response method
            - Prints the AI response to stdout
            - Handles any exceptions that occur during AI processing
        """
        try:
            # Check if AI instance has get_response method
            if hasattr(self.ai_instance, 'get_response'):
                ret, response = self.ai_instance.get_response(query)
                if not ret:
                    print("Error in AI response : ", response)
                else:
                    print(f"\n{response}\n")
            else:
                print("\nAI: This AI backend doesn't support chat queries.\n")
        except Exception as e:
            print(f"\nAI Error: Failed to get response - {str(e)}\n")

