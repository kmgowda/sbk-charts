#!/usr/local/bin/python3
# Copyright (c) KMG. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
##
"""
SBK AI Analysis Module

This module provides AI-powered analysis capabilities for storage benchmark results.
It extends the SbkMultiCharts class to add AI-generated performance analysis
for storage system benchmarks, including throughput and latency analysis.

The module integrates with Hugging Face models to provide intelligent insights
into storage performance metrics.
"""

from typing import final

from openpyxl import load_workbook

from src.ai.discover import discover_custom_ai_classes
from src.charts import constants
from src.charts.utils import is_r_num_sheet, get_columns_from_worksheet, get_storage_name_from_worksheet
from src.charts.utils import get_time_unit_from_worksheet, get_action_name_from_worksheet
from src.sheets import constants as sheets_constants
from src.charts.multicharts import SbkMultiCharts
from openpyxl.styles import Font, Border, Side, Alignment   
import textwrap

from src.stat.storage import StorageStat

# Log the full exception for debugging
import traceback

# Warning message about AI-generated content reliability
warning_msg = ("The AI may hallucinate !. "
              "The summary generated by generative AI models may not be complete and accurate. "
              "It's recommended to analyze the graphs along with the generated summary.")


def get_t_num_sheet_name(r_num_name):
    """Return the corresponding T-sheet name for an R-sheet name.

    Example: 'R1' -> 'T1'

    Parameters
    - r_num_name (str): R-sheet name

    Returns
    - str: corresponding T-sheet name
    """
    return sheets_constants.T_PREFIX + r_num_name[1:]


def get_columns_values(ws):
    """
    Extract column values from a worksheet, excluding metadata columns.

    Args:
        ws (openpyxl.worksheet.worksheet.Worksheet): The worksheet to extract data from.

    Returns:
        dict: Dictionary mapping column names to their values.
    """
    columns = get_columns_from_worksheet(ws)
    ret = dict()
    for col_name, col_idx in columns.items():
        if col_name not in [constants.ID, constants.HEADER, constants.TYPE,
                          constants.STORAGE, constants.ACTION, constants.LATENCY_TIME_UNIT]:
            values = []
            for row in range(2, ws.max_row + 1):
                cell_value = ws.cell(row=row, column=col_idx).value
                values.append(cell_value)
            ret[col_name] = values
    return ret


@final
class SbkAI:
    """
    SBK AI Analysis class that extends SbkMultiCharts to provide AI-powered analysis.
    
    This class adds AI-generated performance analysis to storage benchmark results,
    including throughput and latency analysis using Hugging Face models.
    
    Attributes:
        version (str): Version information for the benchmark.
        ai (HuggingFace): Instance of HuggingFace for AI analysis.
    """
    
    def __init__(self, version):
        """
        Initialize the SbkAI instance.
        
        Args:
            version (str): Version information for the benchmark.
            file (str): Path to the benchmark results file.
        """
        self.version = version
        self.classes = discover_custom_ai_classes()
        self.ai_instance = None
        self.enable_ai = False
        self.args = None
        self.wb = None

    def add_args(self, parser):
        parser.add_argument( "-ai", "--enable-ai", "Enable AI analysis", default = False)
        parser.add_argument( "-class", "--ai-class", "AI class to use, available classes : [ " + ", ".join(self.classes.keys()) + "]",
                             default = "HuggingFace")

    def parse_args(self, args):
        self.args = args
        self.enable_ai = self.args.enable_ai
        if self.args.ai_class.lower() not in self.classes.keys():
            raise ValueError(f"Invalid AI class: {self.args.ai_class}")
        self.ai_instance = self.classes[self.args.ai_class.lower()]()

    def load_workbook(self):
        self.wb = load_workbook(self.args.ofile)

    def save_workbook(self):
        self.wb.save(self.args.ofile)

    def get_storage_stats(self):
        """
        Collect and organize storage statistics from all worksheets.
        
        Returns:
            list: List of StorageStat objects containing performance metrics
                  for each storage system in the benchmark.
        """
        stats = list()
        for name in self.wb.sheetnames:
            if is_r_num_sheet(name):
                ws = self.wb[name]
                storage = get_storage_name_from_worksheet(ws)
                timeunit = get_time_unit_from_worksheet(ws)
                action = get_action_name_from_worksheet(ws)
                # Get all the columns of R<Count>
                regular = get_columns_values(ws)
                # Get all the columns of T<Count>
                t_name = get_t_num_sheet_name(name)
                ws = self.wb[t_name]
                total = get_columns_values(ws)
                stats.append(StorageStat(storage, timeunit, action, regular, total))
        return stats

    def add_ai_analysis(self):
        """
        Create a summary sheet with AI-generated performance analysis.
        
        This method runs AI analysis methods in parallel to improve performance.
        It collects throughput and latency analysis from the AI instance and
        stores the results in a dictionary.
        
        Returns:
            dict: Dictionary containing the analysis results with keys:
                - 'throughput': Tuple of (status, analysis) for throughput
                - 'latency': Tuple of (status, analysis) for latency
        """
        import concurrent.futures
        from concurrent.futures import ThreadPoolExecutor
        
        # Set storage statistics for AI analysis
        self.ai_instance.set_storage_stats(self.get_storage_stats())
        
        results = {}
        
        def run_analysis(method_name):
            try:
                method = getattr(self.ai_instance, method_name)
                result = method()
                return method_name,result
            except Exception as e:
                print(f"Error in {method_name}: {str(e)}")
                return method_name, (False, str(e))
        
        # List of AI analysis methods to run in parallel
        analysis_methods = [
            'get_throughput_analysis',
            'get_latency_analysis',
            'get_model_description'
        ]
        
        # Run all analysis methods in parallel
        with ThreadPoolExecutor(max_workers=len(analysis_methods)) as executor:
            future_to_method = {
                executor.submit(run_analysis, method): method 
                for method in analysis_methods
            }

            return_on_error = False
            for future in concurrent.futures.as_completed(future_to_method):
                method_name, (status, analysis) = future.result()
                results[method_name] = [status, analysis]
                if not status:
                    print(f"Error in {method_name}: {analysis}")
                    return_on_error = True

        if return_on_error:
            return

        # Format and add AI analysis to the worksheet
        try:
            sheet = self.wb["Summary"]

            # Configure column H width to accommodate 120 characters
            sheet.column_dimensions['H'].width = 120 * 0.90
            
            # Add AI warning section with proper formatting
            max_row = sheet.max_row + 3  # Add spacing before the warning
            
            # Format and add the warning message
            warn_cell = sheet.cell(row=max_row, column=8)
            warn_cell.value = warning_msg
            warn_cell.font = Font(size=16, bold=True, color="FFFF0000")  # Red bold text
            warn_cell.alignment = Alignment(wrap_text=True, vertical='top')
            
            # Calculate optimal row height for the warning message
            warning_wrapped_lines = []
            for line in warning_msg.split('\n'):
                warning_wrapped_lines.extend(textwrap.wrap(line, width=120))
            
            # Set row height with minimum of 35 points
            warn_row_height = max(35, len(warning_wrapped_lines) * 35)
            sheet.row_dimensions[max_row].height = warn_row_height

            # Add AI Performance Analysis section header
            max_row = sheet.max_row + 2
            title_cell = sheet.cell(row=max_row, column=7)
            title_cell.value = "AI Performance Analysis"
            title_cell.font = Font(size=18, bold=True, color="FF0000")
            
            # Add model description
            dec_cell = sheet.cell(row=max_row, column=8)
            dec_cell.value = results['get_model_description'][1]
            dec_cell.font = Font(size=16, color="00CF00")  # Green text for model info

            # Add Throughput Analysis section
            throughput_header_row = max_row + 2
            cell = sheet.cell(row=throughput_header_row, column=7)
            cell.value = "Throughput Analysis"
            cell.font = Font(size=16, bold=True, color="EE00FF")  # Purple header
            
            # Add throughput analysis content with formatting
            cell = sheet.cell(row=throughput_header_row, column=8)
            throughput_analysis = results['get_throughput_analysis'][1]
            cell.value = throughput_analysis
            cell.font = Font(size=14, color="FF800000")  # Dark red text
            cell.border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            cell.alignment = Alignment(wrap_text=True, vertical='top')
            
            # Calculate and set optimal row height for throughput analysis
            wrapped_lines = []
            for line in throughput_analysis.split('\n'):
                wrapped_lines.extend(textwrap.wrap(line, width=120))
            
            row_height = max(25, len(wrapped_lines) * 25)
            sheet.row_dimensions[throughput_header_row].height = row_height

            # Add Latency Analysis section
            latency_row = sheet.max_row + 1
            
            # Format and add latency analysis header
            cell = sheet.cell(row=latency_row, column=7)
            cell.value = "Latency Analysis"
            cell.font = Font(size=16, bold=True, color="00AA00")  # Green header
            
            # Add latency analysis content with formatting
            cell = sheet.cell(row=latency_row, column=8)
            latency_analysis = results['get_latency_analysis'][1]
            cell.value = latency_analysis
            cell.font = Font(size=14, color="FF000080")  # Dark blue text
            cell.border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            cell.alignment = Alignment(wrap_text=True, vertical='top')
            
            # Calculate and set optimal row height for latency analysis
            latency_wrapped_lines = []
            for line in latency_analysis.split('\n'):
                latency_wrapped_lines.extend(textwrap.wrap(line, width=120))
            
            latency_row_height = max(25, len(latency_wrapped_lines) * 25)
            sheet.row_dimensions[latency_row].height = latency_row_height

        except Exception as e:
            print(f"Error adding analysis to summary sheet: {str(e)}")
            traceback.print_exc()
        return

    def create_graphs(self):
        """
        Generate all performance graphs and AI analysis for the benchmark results.
        
        This method orchestrates the creation of various performance graphs and
        AI analysis, then saves the results to the output file.
        
        The method creates the following types of graphs:
        - Throughput graphs (MB/s and records/s)
        - Latency comparison graphs
        - Write/Read metrics graphs
        - Percentile analysis graphs
        - Comparative analysis graphs
        
        After generating all graphs and analysis, it saves the results to the
        Excel workbook and prints a confirmation message.
        """
        excel_graphs =  SbkMultiCharts(self.version, self.args.ofile)
        excel_graphs.create_graphs()
        if not self.enable_ai:
            print("AI is not enabled")
        else:
            self.load_workbook()
            self.add_ai_analysis()
            self.save_workbook()
            print(f"File updated with graphs and AI documentation: {self.args.ofile}")
