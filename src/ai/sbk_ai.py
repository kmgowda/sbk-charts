#!/usr/local/bin/python3
# Copyright (c) KMG. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
##
"""
SBK AI Analysis Module

This module provides AI-powered analysis capabilities for storage benchmark results.
It extends the SbkMultiCharts class to add AI-generated performance analysis
for storage system benchmarks, including throughput and latency analysis.

The module integrates with Hugging Face models to provide intelligent insights
into storage performance metrics.
"""
import time
from typing import final

from openpyxl import load_workbook

from src.ai.discover import discover_custom_ai_classes
from src.charts import constants
from src.charts.utils import is_r_num_sheet, get_columns_from_worksheet, get_storage_name_from_worksheet
from src.charts.utils import get_time_unit_from_worksheet, get_action_name_from_worksheet
from src.sheets import constants as sheets_constants
from openpyxl.styles import Font, Border, Side, Alignment   
import textwrap

from src.stat.storage import StorageStat
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor

# Log the full exception for debugging
import traceback

# Warning message about AI-generated content reliability
warning_msg = ("The AI may hallucinate !. "
              "The summary generated by generative AI models may not be complete and accurate. "
              "It's recommended to analyze the graphs along with the generated summary.")


def get_t_num_sheet_name(r_num_name):
    """Return the corresponding T-sheet name for an R-sheet name.

    Example: 'R1' -> 'T1'

    Parameters
    - r_num_name (str): R-sheet name

    Returns
    - str: corresponding T-sheet name
    """
    return sheets_constants.T_PREFIX + r_num_name[1:]


def get_columns_values(ws):
    """
    Extract column values from a worksheet, excluding metadata columns.

    Args:
        ws (openpyxl.worksheet.worksheet.Worksheet): The worksheet to extract data from.

    Returns:
        dict: Dictionary mapping column names to their values.
    """
    columns = get_columns_from_worksheet(ws)
    ret = dict()
    for col_name, col_idx in columns.items():
        if col_name not in [constants.ID, constants.HEADER, constants.TYPE,
                          constants.STORAGE, constants.ACTION, constants.LATENCY_TIME_UNIT]:
            values = []
            for row in range(2, ws.max_row + 1):
                cell_value = ws.cell(row=row, column=col_idx).value
                values.append(cell_value)
            ret[col_name] = values
    return ret


@final
class SbkAI:
    """
    SBK AI Analysis class that extends SbkMultiCharts to provide AI-powered analysis.
    
    This class adds AI-generated performance analysis to storage benchmark results,
    including throughput and latency analysis using Hugging Face models.
    """

    def __init__(self):
        self.classes = discover_custom_ai_classes()
        self.ai_instance_map = dict()
        self.subparsers = None
        self.file =  None
        self.ai_instance = None
        self.web = None

    def add_args(self, parser):
        self.subparsers = parser.add_subparsers(dest="ai_class", help="Available sub-commands", required=False)
        parser.set_defaults(ai_class=None)
        for name, cls in self.classes.items():
            try:
                subp = self.subparsers.add_parser(name)
                self.ai_instance_map[name.lower()] = cls()
                self.ai_instance_map[name.lower()].add_args(subp)
            except Exception:
                # don't break arg registration if a class has issues; log for debugging
                traceback.print_exc()


    def parse_args(self, args):
        self.file = args.ofile
        if args.ai_class:
            self.ai_instance = self.ai_instance_map[args.ai_class.lower()]
            self.ai_instance.parse_args(args)

    def load_workbook(self):
        self.wb = load_workbook(self.file)

    def save_workbook(self):
        self.wb.save(self.file)

    def get_storage_stats(self):
        """
        Collect and organize storage statistics from all worksheets.
        
        Returns:
            list: List of StorageStat objects containing performance metrics
                  for each storage system in the benchmark.
        """
        stats = list()
        for name in self.wb.sheetnames:
            if is_r_num_sheet(name):
                ws = self.wb[name]
                storage = get_storage_name_from_worksheet(ws)
                timeunit = get_time_unit_from_worksheet(ws)
                action = get_action_name_from_worksheet(ws)
                # Get all the columns of R<Count>
                regular = get_columns_values(ws)
                # Get all the columns of T<Count>
                t_name = get_t_num_sheet_name(name)
                ws = self.wb[t_name]
                total = get_columns_values(ws)
                stats.append(StorageStat(storage, timeunit, action, regular, total))
        return stats

    def add_ai_analysis(self):
        """
        Create a summary sheet with AI-generated performance analysis.
        
        This method runs AI analysis methods in parallel to improve performance.
        It collects throughput and latency analysis from the AI instance and
        stores the results in a dictionary.
        
        Returns:
            dict: Dictionary containing the analysis results with keys:
                - 'throughput': Tuple of (status, analysis) for throughput
                - 'latency': Tuple of (status, analysis) for latency
        """
        # Set storage statistics for AI analysis
        self.ai_instance.set_storage_stats(self.get_storage_stats())
        
        results = {}
        
        def run_analysis(method_name):
            try:
                method = getattr(self.ai_instance, method_name)
                result = method()
                return method_name,result
            except Exception as e:
                print(f"Error in {method_name}: {str(e)}")
                return method_name, (False, str(e))
        
        # List of AI analysis methods to run in parallel
        analysis_methods = [
            'get_throughput_analysis',
            'get_latency_analysis',
            'get_total_mb_analysis',
            'get_percentile_histogram_analysis',
        ]

        # Run all analysis methods in parallel
        print("Starting AI analysis. This may take a few minutes...", flush=True)
        start_time = time.time()
        timeout_seconds = 300  # 5 minutes total timeout

        # Create a dictionary to store results
        results = {}

        # Submit all tasks
        with ThreadPoolExecutor(max_workers=len(analysis_methods)) as executor:
            # Submit all tasks and store futures
            future_to_method = {executor.submit(run_analysis, method): method
                                for method in analysis_methods}

            # Process completed tasks as they finish
            while future_to_method and (time.time() - start_time) < timeout_seconds:
                # Wait for the next future to complete, with a timeout
                done, _ = concurrent.futures.wait(
                    future_to_method.keys(),
                    timeout=2.0,  # Check every second for timeouts
                    return_when=concurrent.futures.FIRST_COMPLETED
                )

                # Process completed futures
                for future in done:
                    method_name = future_to_method.pop(future)
                    try:
                        # Get the result with a small timeout to prevent hanging
                        result_method, result = future.result(timeout=1.0)
                        results[result_method] = result
                        print(f"✓ Completed {result_method}")
                    except concurrent.futures.TimeoutError:
                        print(f"⚠️ Timeout waiting for {method_name}, skipping...")
                    except Exception as e:
                        print(f"⚠️ Error in {method_name}: {str(e)}")
                        results[method_name] = (False, str(e))

                # Print progress
                remaining = len(future_to_method)
                if remaining > 0:
                    print(f"⏳ Waiting for {remaining} more analysis tasks...")

            # Cancel any remaining futures
            for future in future_to_method:
                future.cancel()

            # If we timed out, add placeholders for any missing results
            for method_name in analysis_methods:
                if method_name not in results:
                    results[method_name] = (False, "Analysis timed out or failed")

        print()

        # Format and add AI analysis to the worksheet
        try:
            sheet = self.wb["Summary"]

            # Configure column H width to accommodate 120 characters
            sheet.column_dimensions['H'].width = 120 * 0.90
            
            # Add AI warning section with proper formatting
            max_row = sheet.max_row + 3  # Add spacing before the warning
            
            # Format and add the warning message
            warn_cell = sheet.cell(row=max_row, column=8)
            warn_cell.value = warning_msg
            warn_cell.font = Font(size=16, bold=True, color="FFFF0000")  # Red bold text
            warn_cell.alignment = Alignment(wrap_text=True, vertical='top')
            
            # Calculate optimal row height for the warning message
            warning_wrapped_lines = []
            for line in warning_msg.split('\n'):
                warning_wrapped_lines.extend(textwrap.wrap(line, width=120))
            
            # Set row height with minimum of 35 points
            warn_row_height = max(35, len(warning_wrapped_lines) * 35)
            sheet.row_dimensions[max_row].height = warn_row_height

            # Add AI Performance Analysis section header
            max_row = sheet.max_row + 2
            title_cell = sheet.cell(row=max_row, column=7)
            title_cell.value = "AI Performance Analysis"
            title_cell.font = Font(size=18, bold=True, color="FF0000")
            
            # Add model description
            dec_cell = sheet.cell(row=max_row, column=8)
            dec_cell.value = self.ai_instance.get_model_description()[1]
            dec_cell.font = Font(size=16, color="00CF00")  # Green text for model info

            # Add Throughput Analysis section
            throughput_header_row = max_row + 2
            cell = sheet.cell(row=throughput_header_row, column=7)
            cell.value = "Throughput Analysis"
            cell.font = Font(size=16, bold=True, color="EE00FF")  # Purple header
            
            # Add throughput analysis content with formatting
            cell = sheet.cell(row=throughput_header_row, column=8)
            throughput_analysis = results['get_throughput_analysis'][1]
            cell.value = throughput_analysis
            cell.font = Font(size=14, color="FF800000")  # Dark red text
            cell.border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            cell.alignment = Alignment(wrap_text=True, vertical='top')
            
            # Calculate and set optimal row height for throughput analysis
            wrapped_lines = []
            for line in throughput_analysis.split('\n'):
                wrapped_lines.extend(textwrap.wrap(line, width=120))
            
            row_height = max(25, len(wrapped_lines) * 25)
            sheet.row_dimensions[throughput_header_row].height = row_height

            # Add Latency Analysis section
            latency_row = sheet.max_row + 1
            
            # Format and add latency analysis header
            cell = sheet.cell(row=latency_row, column=7)
            cell.value = "Latency Analysis"
            cell.font = Font(size=16, bold=True, color="00AA00")  # Green header
            
            # Add latency analysis content with formatting
            cell = sheet.cell(row=latency_row, column=8)
            latency_analysis = results['get_latency_analysis'][1]
            cell.value = latency_analysis
            cell.font = Font(size=14, color="FF000080")  # Dark blue text
            cell.border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            cell.alignment = Alignment(wrap_text=True, vertical='top')
            
            # Calculate and set optimal row height for latency analysis
            latency_wrapped_lines = []
            for line in latency_analysis.split('\n'):
                latency_wrapped_lines.extend(textwrap.wrap(line, width=120))
            
            latency_row_height = max(25, len(latency_wrapped_lines) * 25)
            sheet.row_dimensions[latency_row].height = latency_row_height
            
            # Add Total MB Analysis section
            mb_row = sheet.max_row + 1
            
            # Format and add total MB analysis header
            cell = sheet.cell(row=mb_row, column=7)
            cell.value = "Total MB Analysis"
            cell.font = Font(size=16, bold=True, color="0000FF")  # Blue header
            
            # Add total MB analysis content with formatting
            cell = sheet.cell(row=mb_row, column=8)
            mb_analysis = results['get_total_mb_analysis'][1]
            cell.value = mb_analysis
            cell.font = Font(size=14, color="008000")  # Green text
            cell.border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            cell.alignment = Alignment(wrap_text=True, vertical='top')
            
            # Calculate and set optimal row height for total MB analysis
            mb_wrapped_lines = []
            for line in mb_analysis.split('\n'):
                mb_wrapped_lines.extend(textwrap.wrap(line, width=120))
            
            mb_row_height = max(25, len(mb_wrapped_lines) * 25)
            sheet.row_dimensions[mb_row].height = mb_row_height
            
            # Add Percentile Histogram Analysis section
            percentile_row = sheet.max_row + 1  # Add an extra blank row
            
            # Format and add percentile histogram analysis header
            cell = sheet.cell(row=percentile_row, column=7)
            cell.value = "Percentile Histogram Analysis"
            cell.font = Font(size=16, bold=True, color="8B008B")  # Dark magenta header
            
            # Add percentile histogram analysis content with formatting
            cell = sheet.cell(row=percentile_row, column=8)
            percentile_analysis = results['get_percentile_histogram_analysis'][1]
            cell.value = percentile_analysis
            cell.font = Font(size=14, color="8B4513")  # Saddle brown text
            cell.border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            cell.alignment = Alignment(wrap_text=True, vertical='top')
            
            # Calculate and set optimal row height for percentile histogram analysis
            percentile_wrapped_lines = []
            for line in percentile_analysis.split('\n'):
                percentile_wrapped_lines.extend(textwrap.wrap(line, width=120))
            
            percentile_row_height = max(25, len(percentile_wrapped_lines) * 25)
            sheet.row_dimensions[percentile_row].height = percentile_row_height

        except Exception as e:
            print(f"Error adding analysis to summary sheet: {str(e)}")
            traceback.print_exc()

        return True

    def add_performance_details(self):
        """
        Generate all performance graphs and AI analysis for the benchmark results.
        
        This method orchestrates the creation of various performance graphs and
        AI analysis, then saves the results to the output file.
        
        The method creates the following types of graphs:
        - Throughput graphs (MB/s and records/s)
        - Latency comparison graphs
        - Write/Read metrics graphs
        - Percentile analysis graphs
        - Comparative analysis graphs
        
        After generating all graphs and analysis, it saves the results to the
        Excel workbook and prints a confirmation message.
        """
        if not self.ai_instance:
            print("AI is not enabled!. you can use the subcommands ["+" ".join(self.classes.keys())+"] to enable it.")
        else:
            self.load_workbook()
            if self.add_ai_analysis():
                print(f"File updated with graphs and AI documentation: {self.file}")
            self.save_workbook()

